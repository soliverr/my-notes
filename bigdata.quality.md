---
id: yrvad5ooqgge7nsjr1ovizj
title: BigData Quality Assurance Models and Methods
desc: ''
updated: 1646459484884
created: 1642743924451
---

# Модели качества данных

## Источники

* [Big Data Quality Assurance](https://itnext.io/big-data-quality-assurance-635c368a3e28)
* [Big Data Quality Modeling And Validation](https://scholarworks.sjsu.edu/cgi/viewcontent.cgi?article=8445&context=etd_theses)
* [Monitoring Data Quality in a Data Lake Using Great Expectations and Allure-Built Serverless](https://towardsdatascience.com/monitoring-data-quality-in-a-data-lake-using-great-expectations-and-allure-built-serverless-47fa1791af6a)
* [Scalable Architecture for Automating Machine Learning Model Monitoring](http://kth.diva-portal.org/smash/get/diva2:1464577/FULLTEXT01.pdf)

## Проекты

* [Apache Griffin](https://griffin.apache.org/)
    * https://github.com/apache/griffin
    * https://cwiki.apache.org/confluence/display/GRIFFIN/Apache+Griffin - пустая практически
    * https://github.com/apache/griffin/blob/master/griffin-doc/ui/user-guide.md - полезная инфа
* [Great Expectations](https://
    * https://github.com/great-expectations/great_expectations
    * https://medium.com/@expectgreatdata/down-with-pipeline-debt-introducing-great-expectations-862ddc46782a
    * https://www.youtube.com/channel/UCpAZim7RRRDFxj2OlEdWsLQ
* [Amazon Deeque](https://github.com/awslabs/deequ)
* [Pandas Profiling](https://github.com/pandas-profiling/pandas-profiling)
* [popmon](https://github.com/ing-bank/popmon)
* [DataCleaner](https://datacleaner.github.io/)

## Постановка задачи

<https://telegra.ph/Model-kachestva-dannyh-v-Hadoop-Postanovka-zadachi-01-21>

Модель качества данных для Hadoop должна быть реализована как распределённый вычислительный алгоритм, поддерживающий возможность расширения вычислительных модулей.

Модель качества является иерархической и многофакторной, то есть метрики модели могут изменяться по составу. Метрики могут описывать точность данных, завершённость (замкнутость) и согласованность данных, непрерывность поступления данных во времени, уникальность и валидность данных и другие параметры.

Иерархичность заключается в том, что данные поступают из одного или цепочки (конвейера, pipeline) источников, которые могут вносить искажения в исходные данные намеренно или случайно. Поэтому, модель данных должна содержать базовые параметры качества источников данных. При ухудшении качества источника данных не имеет смысла расчитывать параметры качества выше по иерархии (например, согласованность данных).

### Модель качества источника данных

Источники данных могут быть нескольких типов:

* источники потоковых данных - данные поступают из источника непрерывно в реальном масштабе времени
* источники пакетных данных - данные поступают из источника порциями, в результате работы конвейера (pipeline) и/или процедур ETL
* источники разреженных данных - данные поступают из источника по запросу пользователя, при этом формат данных каждый раз слабо или значительно изменяется, хотя с точки зрения пользователя, это одни и те же данные (например, загрузка данных из электронных таблиц)

Каждый источник имеет свои операционные параметры, которые должны использоваться в модели качества источника данных. Кроме того, исходя из природы данных, схема данных (то есть, формат, в котором данные поступают) может с течением времени изменяться. Поэтому модификации в схеме данных являются существенным параметром модели.

### Вычислительная реализация

Модель качества данных должна быть построена на принципах распределённых вычислений, при этом могут быть распределены как вычисления отдельных параметров модели, так и сами вычислительные операции для вычисления параметра.

Необходимо провести анализ существующих фреймворков и оценить их пригодность для реализации распределённой модели качества.

#### Реализация на Python

Предлагается оценить следующие фреймворки:

* pandas
* koalas
* DASK
* pySpark

#### Реализация на Scala

Предлагается оценить следующие фреймворки:

* Spark
* Akka
* Alpakka

### Системная архитекутра модели качества

Модель качества подразумевает создание внутреннего представления, в котором публикуются результаты вычислений - параметры качества. Параметры могут объединяться в группы и иметь иерархическую структуру. Рекомендуется рассмотреть графовые иерархические модели представления и хранения данных.

Необходимо гарантировать, что каждый параметр (группа параметров) расчитывается **только одним вычислительным алгоритмом**, при этом сам вычислительный процесс (алгоритм расчёта параметра) должен рассматриваться как источник данных, имеющий свои параметры качества (успешный, неуспешный расчёт).

Результаты вычислений должны сохраняться и восстанавливаться после системных сбоев в инфраструктуре вычислительного кластера (отказ и перезагрузка вычислительных узлов).

Результаты вычислений должны публиковаться в виде сервиса (REST API) и выгружаться в различные приёмники: реляционные базы данных, потоки данных Kafka, сообщаться в другие внешние системы (Web-hooks).




