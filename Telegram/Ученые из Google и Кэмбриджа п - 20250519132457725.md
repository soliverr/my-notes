**Forwarded from [Data Secrets](https://t.me/data_secrets/6930)**

![[photo_135300464_5 - 20250519132457705.jpg]]

**Ученые из Google и Кэмбриджа предложили вид модели, которая мыслит образами, а не текстом**

Человек часто мыслит образами / картинками / схемами. Особенно, когда речь идет о каких-нибудь математических задачах или алгоритмах. Модельки пока так не умеют, у них весь ризонинг в тексте. 

Но попытки научить LM чему-то похожему есть: вот сегодня как раз вышла статья под названием "Visual Planning: Let’s Think Only with Images". В ней исследователи научили модель проходить лабиринты, рассуждая при этом только картинками. Вот как это было:

1. Сначала модели показывали много-много картинок лабиринтов и учили ее предсказывать какой-нибудь любой возможный следующий шаг. Ну, например, подаем картинку агента, который стоит в клетке B. По этой картинке модель должна сгенерировать следующую, где агент стоит на любой из доступных соседних клеток.

2. Затем учили предсказывать уже не рандомный, а правильный следующий шаг. Здесь у нас уже RL (на предыдущем шаге был обычный файнтюнинг). За правильное действие выдаем награду +1, за неправильное 0, за недопустимое -5. 

Модель проходит по нескольку картинок за эпизод, собирает награды и многократко обновляет свою политику. В итоге получаем **ризонер, который умеет проходить лабиринты, рассуждая без текста**. 

Самое интересное: **на всех тестах VP обходит даже продвинутый Gemini 2.5 Pro think**, и не на пару процентов, а в полтора-два раза. 

Вот бы с какой-нибудь сложной геометрией такое потестили

huggingface.co/papers/2505.11409